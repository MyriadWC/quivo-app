{"ast":null,"code":"export var calcLevelOrig = function calcLevelOrig(n, tot_n) {\n  var wordsInLevel = Math.floor(tot_n / 100);\n  var floatLevel = n / wordsInLevel;\n  var level = Math.floor(floatLevel);\n  var levelResidual = floatLevel - level;\n  var knownWordsInLevel = n - level * wordsInLevel;\n  level = level + 1;\n  return {\n    level: level,\n    levelResidual: levelResidual,\n    wordsInLevel: wordsInLevel,\n    knownWordsInLevel: knownWordsInLevel\n  };\n};\nexport var calcLevel = function calcLevel(n, tot_n) {\n  function findLastSmallerIndex(arr, n) {\n    var left = 0;\n    var right = arr.length - 1;\n    var result = -1;\n    while (left <= right) {\n      var mid = Math.floor((left + right) / 2);\n      if (arr[mid] < n) {\n        result = mid;\n        left = mid + 1;\n      } else {\n        right = mid - 1;\n      }\n    }\n    return result;\n  }\n  var _generateBuckets = generateBuckets(tot_n, 100, 50),\n    buckets = _generateBuckets.buckets,\n    cumBuckets = _generateBuckets.cumBuckets;\n  var levelIdx = findLastSmallerIndex(cumBuckets, n) + 1;\n  var knownWordsInLevel = n - (levelIdx == 0 ? 0 : cumBuckets[levelIdx - 1]);\n  var wordsInLevel = buckets[levelIdx];\n  var level = levelIdx + 1;\n  return {\n    level: level,\n    wordsInLevel: wordsInLevel,\n    knownWordsInLevel: knownWordsInLevel\n  };\n};\nexport var frequencyIndexToComprehensionPercentage = function frequencyIndexToComprehensionPercentage(n, coeffs) {\n  var floatCoeffs = coeffs.map(function (item) {\n    return parseFloat(item);\n  });\n  return n == 0 ? 0 : Math.round(-83.32317585 + 191.39405783 / (1 + Math.E ** (-0.39771826 * n ** 0.20018198)));\n};\nexport var sumWordCounts = function sumWordCounts(wordCounts) {\n  return Object.values(wordCounts).reduce(function (a, b) {\n    return a + b;\n  }, 0);\n};\nexport var generateBuckets = function generateBuckets(nCorpus, nBuckets, firstTerm) {\n  var a = firstTerm;\n  var r = 1.01;\n  var epsilon = 0.00001;\n  var low = 1,\n    high = 2;\n  while (high - low > epsilon) {\n    r = (low + high) / 2;\n    var sum = a * (1 - Math.pow(r, nBuckets)) / (1 - r);\n    if (sum > nCorpus) {\n      high = r;\n    } else {\n      low = r;\n    }\n  }\n  var buckets = [];\n  var bucketSize = a;\n  for (var i = 0; i < nBuckets; i++) {\n    buckets.push(Math.round(bucketSize));\n    bucketSize *= r;\n  }\n  var bucketSum = buckets.reduce(function (a, b) {\n    return a + b;\n  }, 0);\n  var outstanding = nCorpus - bucketSum;\n  buckets[buckets.length - 1] += outstanding;\n  var cumBuckets = buckets.map(function (sum) {\n    return function (value) {\n      return sum += value;\n    };\n  }(0));\n  return {\n    buckets: buckets,\n    cumBuckets: cumBuckets\n  };\n};","map":{"version":3,"names":["calcLevelOrig","n","tot_n","wordsInLevel","Math","floor","floatLevel","level","levelResidual","knownWordsInLevel","calcLevel","findLastSmallerIndex","arr","left","right","length","result","mid","_generateBuckets","generateBuckets","buckets","cumBuckets","levelIdx","frequencyIndexToComprehensionPercentage","coeffs","floatCoeffs","map","item","parseFloat","round","E","sumWordCounts","wordCounts","Object","values","reduce","a","b","nCorpus","nBuckets","firstTerm","r","epsilon","low","high","sum","pow","bucketSize","i","push","bucketSum","outstanding","value"],"sources":["C:/Users/Toby Usher/Documents/dev/quivo-app/frontend/utils/functions.ts"],"sourcesContent":["export const calcLevelOrig = (n: number, tot_n: number) => {\r\n\r\n    const wordsInLevel = Math.floor(tot_n / 100);\r\n\r\n    const floatLevel = n / wordsInLevel;\r\n    let level = Math.floor(floatLevel);\r\n    const levelResidual = floatLevel - level;\r\n    const knownWordsInLevel = n - (level * wordsInLevel);\r\n    // Level should start at 1 not 0\r\n    level = level + 1;\r\n\r\n    return { level, levelResidual, wordsInLevel, knownWordsInLevel};\r\n}\r\n\r\nexport const calcLevel = (n: number, tot_n: number) => {\r\n\r\n    function findLastSmallerIndex(arr, n) {\r\n        // Given an increasing array of numbers, use binary search\r\n        // to find the index of the last number that is smaller than\r\n        // n\r\n        let left = 0;\r\n        let right = arr.length - 1;\r\n        let result = -1; // Initialize with an invalid index\r\n    \r\n        while (left <= right) {\r\n            const mid = Math.floor((left + right) / 2);\r\n    \r\n            if (arr[mid] < n) {\r\n                // Update result and search right half\r\n                result = mid;\r\n                left = mid + 1;\r\n            } else {\r\n                // Search left half\r\n                right = mid - 1;\r\n            }\r\n        }\r\n    \r\n        return result;\r\n    }\r\n    \r\n    // I shouldn't be generating the buckets each time. Should do this when language changes and store\r\n    const {buckets, cumBuckets} = generateBuckets(tot_n, 100, 50);\r\n    \r\n    //level is the index of the\r\n    const levelIdx = findLastSmallerIndex(cumBuckets, n) + 1;\r\n    const knownWordsInLevel = n - (levelIdx == 0 ? 0 : cumBuckets[levelIdx - 1]);\r\n    const wordsInLevel = buckets[levelIdx];\r\n    \r\n    // Actual level is one more than the index\r\n    const level = levelIdx + 1;\r\n\r\n    return { level, wordsInLevel, knownWordsInLevel};\r\n}\r\n\r\nexport const frequencyIndexToComprehensionPercentage = (n: number, coeffs: string[]) => {\r\n    // Describes the relationship between n and the percentage of a language\r\n    // someone would know were they to know all the words between the 1st and nth\r\n    // most frequent words in the language.\r\n    // Ex. If someone knew the 1000 most frequently-used words in a language,\r\n    // (n=1000), they could understand f(n) percent of the text in the corpus.\r\n    // TODO: Pass in the custom constants for each language's corpus.\r\n    const floatCoeffs = coeffs.map(item => parseFloat(item));\r\n    //return n == 0 ? 0 : Math.round(floatCoeffs[0] + floatCoeffs[1] / (1 + Math.E**(floatCoeffs[2] * n**floatCoeffs[3])));\r\n    return n == 0 ? 0 : Math.round(-83.32317585 + 191.39405783 / (1 + Math.E**(-0.39771826 * n**0.20018198)));\r\n}\r\n\r\nexport const sumWordCounts = (wordCounts: Record<string, number>) => {\r\n    return Object.values(wordCounts).reduce((a, b) => a + b, 0)\r\n}\r\n\r\nexport const generateBuckets = (nCorpus: number, nBuckets: number, firstTerm: number) => {\r\n    /* Given the number of words in the corpus, I want to generate buckets\r\n    that will allow me to assign a level to the user. I want the buckets to be smaller\r\n    at the start and increase as the user progresses, so it will have to be modelled as\r\n    a geometric series with a common ratio, r, making sure that the sum of all words in all\r\n    levels is still equal to S).\r\n\r\n    The easiest way to do this is by modelling the sum of bucket sizes as:\r\n\r\n    bucket size = a * r^n\r\n\r\n    where S = unique words in corpus\r\n    a = first term\r\n    r = common ratio (need to find)\r\n    n = number of levels\r\n    \r\n    The sum of all terms is:\r\n    \r\n    S = a * ((1 - r^n)/(1-r))\r\n\r\n    since:\r\n\r\n    S = a + ar + ar^2 + ... + ar^n-1\r\n    rS = ar + ar^2 + ar^3 + ... ar^n\r\n    S - rS = a - ar^n\r\n    S = a(1-r^n)/(1-r)\r\n\r\n    An appropriate value of r can be found by choosing an initial guess\r\n    and using binary search to step closer to the correct value, until\r\n    we find an r that generates an S within a chosen tolerance of the\r\n    total words in the corpus.\r\n\r\n    Then this r can be used in the first equation to generate the bucket\r\n    sizes.\r\n    */\r\n\r\n    let a = firstTerm;\r\n    let r = 1.01;  // Initial guess\r\n    let epsilon = 0.00001;  // Tolerance for value of r\r\n\r\n    // Use binary search to find r\r\n    let low = 1, high = 2; // Can probably reduce the high value\r\n\r\n    while (high - low > epsilon) {\r\n        r = (low + high) / 2;\r\n        let sum = a * (1 - Math.pow(r, nBuckets)) / (1 - r);\r\n        if (sum > nCorpus) {\r\n            high = r;\r\n        } else {\r\n            low = r;\r\n        }\r\n    }\r\n\r\n    // Generate the buckets now an appropriate r has been found\r\n    let buckets = [];\r\n    let bucketSize = a;\r\n    for (let i = 0; i < nBuckets; i++) {\r\n        buckets.push(Math.round(bucketSize));\r\n        bucketSize *= r;\r\n    }\r\n\r\n    // Compare sum of buckets to nCorpus\r\n    const bucketSum = buckets.reduce((a, b) => a + b, 0);\r\n    const outstanding = nCorpus - bucketSum;\r\n    \r\n    //add/subtract difference to final level bucket size\r\n    buckets[buckets.length - 1] += outstanding;\r\n\r\n    // Get the cumulative size of all buckets\r\n    const cumBuckets = buckets.map((sum => value => sum += value)(0));\r\n\r\n    return {buckets, cumBuckets};\r\n}"],"mappings":"AAAA,OAAO,IAAMA,aAAa,GAAG,SAAhBA,aAAaA,CAAIC,CAAS,EAAEC,KAAa,EAAK;EAEvD,IAAMC,YAAY,GAAGC,IAAI,CAACC,KAAK,CAACH,KAAK,GAAG,GAAG,CAAC;EAE5C,IAAMI,UAAU,GAAGL,CAAC,GAAGE,YAAY;EACnC,IAAII,KAAK,GAAGH,IAAI,CAACC,KAAK,CAACC,UAAU,CAAC;EAClC,IAAME,aAAa,GAAGF,UAAU,GAAGC,KAAK;EACxC,IAAME,iBAAiB,GAAGR,CAAC,GAAIM,KAAK,GAAGJ,YAAa;EAEpDI,KAAK,GAAGA,KAAK,GAAG,CAAC;EAEjB,OAAO;IAAEA,KAAK,EAALA,KAAK;IAAEC,aAAa,EAAbA,aAAa;IAAEL,YAAY,EAAZA,YAAY;IAAEM,iBAAiB,EAAjBA;EAAiB,CAAC;AACnE,CAAC;AAED,OAAO,IAAMC,SAAS,GAAG,SAAZA,SAASA,CAAIT,CAAS,EAAEC,KAAa,EAAK;EAEnD,SAASS,oBAAoBA,CAACC,GAAG,EAAEX,CAAC,EAAE;IAIlC,IAAIY,IAAI,GAAG,CAAC;IACZ,IAAIC,KAAK,GAAGF,GAAG,CAACG,MAAM,GAAG,CAAC;IAC1B,IAAIC,MAAM,GAAG,CAAC,CAAC;IAEf,OAAOH,IAAI,IAAIC,KAAK,EAAE;MAClB,IAAMG,GAAG,GAAGb,IAAI,CAACC,KAAK,CAAC,CAACQ,IAAI,GAAGC,KAAK,IAAI,CAAC,CAAC;MAE1C,IAAIF,GAAG,CAACK,GAAG,CAAC,GAAGhB,CAAC,EAAE;QAEde,MAAM,GAAGC,GAAG;QACZJ,IAAI,GAAGI,GAAG,GAAG,CAAC;MAClB,CAAC,MAAM;QAEHH,KAAK,GAAGG,GAAG,GAAG,CAAC;MACnB;IACJ;IAEA,OAAOD,MAAM;EACjB;EAGA,IAAAE,gBAAA,GAA8BC,eAAe,CAACjB,KAAK,EAAE,GAAG,EAAE,EAAE,CAAC;IAAtDkB,OAAO,GAAAF,gBAAA,CAAPE,OAAO;IAAEC,UAAU,GAAAH,gBAAA,CAAVG,UAAU;EAG1B,IAAMC,QAAQ,GAAGX,oBAAoB,CAACU,UAAU,EAAEpB,CAAC,CAAC,GAAG,CAAC;EACxD,IAAMQ,iBAAiB,GAAGR,CAAC,IAAIqB,QAAQ,IAAI,CAAC,GAAG,CAAC,GAAGD,UAAU,CAACC,QAAQ,GAAG,CAAC,CAAC,CAAC;EAC5E,IAAMnB,YAAY,GAAGiB,OAAO,CAACE,QAAQ,CAAC;EAGtC,IAAMf,KAAK,GAAGe,QAAQ,GAAG,CAAC;EAE1B,OAAO;IAAEf,KAAK,EAALA,KAAK;IAAEJ,YAAY,EAAZA,YAAY;IAAEM,iBAAiB,EAAjBA;EAAiB,CAAC;AACpD,CAAC;AAED,OAAO,IAAMc,uCAAuC,GAAG,SAA1CA,uCAAuCA,CAAItB,CAAS,EAAEuB,MAAgB,EAAK;EAOpF,IAAMC,WAAW,GAAGD,MAAM,CAACE,GAAG,CAAC,UAAAC,IAAI;IAAA,OAAIC,UAAU,CAACD,IAAI,CAAC;EAAA,EAAC;EAExD,OAAO1B,CAAC,IAAI,CAAC,GAAG,CAAC,GAAGG,IAAI,CAACyB,KAAK,CAAC,CAAC,WAAW,GAAG,YAAY,IAAI,CAAC,GAAGzB,IAAI,CAAC0B,CAAC,KAAG,CAAC,UAAU,GAAG7B,CAAC,IAAE,UAAU,CAAC,CAAC,CAAC;AAC7G,CAAC;AAED,OAAO,IAAM8B,aAAa,GAAG,SAAhBA,aAAaA,CAAIC,UAAkC,EAAK;EACjE,OAAOC,MAAM,CAACC,MAAM,CAACF,UAAU,CAAC,CAACG,MAAM,CAAC,UAACC,CAAC,EAAEC,CAAC;IAAA,OAAKD,CAAC,GAAGC,CAAC;EAAA,GAAE,CAAC,CAAC;AAC/D,CAAC;AAED,OAAO,IAAMlB,eAAe,GAAG,SAAlBA,eAAeA,CAAImB,OAAe,EAAEC,QAAgB,EAAEC,SAAiB,EAAK;EAoCrF,IAAIJ,CAAC,GAAGI,SAAS;EACjB,IAAIC,CAAC,GAAG,IAAI;EACZ,IAAIC,OAAO,GAAG,OAAO;EAGrB,IAAIC,GAAG,GAAG,CAAC;IAAEC,IAAI,GAAG,CAAC;EAErB,OAAOA,IAAI,GAAGD,GAAG,GAAGD,OAAO,EAAE;IACzBD,CAAC,GAAG,CAACE,GAAG,GAAGC,IAAI,IAAI,CAAC;IACpB,IAAIC,GAAG,GAAGT,CAAC,IAAI,CAAC,GAAGhC,IAAI,CAAC0C,GAAG,CAACL,CAAC,EAAEF,QAAQ,CAAC,CAAC,IAAI,CAAC,GAAGE,CAAC,CAAC;IACnD,IAAII,GAAG,GAAGP,OAAO,EAAE;MACfM,IAAI,GAAGH,CAAC;IACZ,CAAC,MAAM;MACHE,GAAG,GAAGF,CAAC;IACX;EACJ;EAGA,IAAIrB,OAAO,GAAG,EAAE;EAChB,IAAI2B,UAAU,GAAGX,CAAC;EAClB,KAAK,IAAIY,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGT,QAAQ,EAAES,CAAC,EAAE,EAAE;IAC/B5B,OAAO,CAAC6B,IAAI,CAAC7C,IAAI,CAACyB,KAAK,CAACkB,UAAU,CAAC,CAAC;IACpCA,UAAU,IAAIN,CAAC;EACnB;EAGA,IAAMS,SAAS,GAAG9B,OAAO,CAACe,MAAM,CAAC,UAACC,CAAC,EAAEC,CAAC;IAAA,OAAKD,CAAC,GAAGC,CAAC;EAAA,GAAE,CAAC,CAAC;EACpD,IAAMc,WAAW,GAAGb,OAAO,GAAGY,SAAS;EAGvC9B,OAAO,CAACA,OAAO,CAACL,MAAM,GAAG,CAAC,CAAC,IAAIoC,WAAW;EAG1C,IAAM9B,UAAU,GAAGD,OAAO,CAACM,GAAG,CAAE,UAAAmB,GAAG;IAAA,OAAI,UAAAO,KAAK;MAAA,OAAIP,GAAG,IAAIO,KAAK;IAAA;EAAA,EAAE,CAAC,CAAC,CAAC;EAEjE,OAAO;IAAChC,OAAO,EAAPA,OAAO;IAAEC,UAAU,EAAVA;EAAU,CAAC;AAChC,CAAC"},"metadata":{},"sourceType":"module","externalDependencies":[]}