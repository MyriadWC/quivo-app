{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have a huge database of french sentences (All under 200 chars) categorised into 1400 clusters. I now need to filter down this dataset to a much smaller dataset of cleaned sentences appropriate for use within the app.\n",
    "\n",
    "I want to filter things like:\n",
    "\n",
    "Websites and email addresses\n",
    "\n",
    "Long strings of the same character, such as Awwwwwwww. Filtering three will discard some roman numerals so four or more is what I chose\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./french_sentences_with_cluster_labels.csv\"\n",
    "\n",
    "df = pd.read_csv(filepath)#, delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          850171\n",
       "sentence    850171\n",
       "cluster     850171\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any sentences with fewer than 70 characters (max already capped at 200)\n",
    "df = df[df['sentence'].str.len() >= 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          640377\n",
       "sentence    640377\n",
       "cluster     640377\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toby Usher\\AppData\\Local\\Temp\\ipykernel_22516\\2219072448.py:2: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_filtered = df[df['sentence'].str.contains(r'([a-z])\\1\\1\\1', regex=True, na=False, case=False)]\n"
     ]
    }
   ],
   "source": [
    "# First get all sentences with three or more of the same roman character in a row\n",
    "df_filtered = df[df['sentence'].str.contains(r'([a-z])\\1\\1\\1', regex=True, na=False, case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          70\n",
       "sentence    70\n",
       "cluster     70\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>3338</td>\n",
       "      <td>Cher M XXXXXX, CANALSAT lance aujourd'hui une ...</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>4178</td>\n",
       "      <td>Rougui est passé par là: il a fait un gros tra...</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23173</th>\n",
       "      <td>27182</td>\n",
       "      <td>Attention : \"La BCD\" nécessite que le format d...</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28796</th>\n",
       "      <td>33661</td>\n",
       "      <td>Mon espérence sur ce peut-être nouveau zelda s...</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40245</th>\n",
       "      <td>47148</td>\n",
       "      <td>Sachant que « XXXX » est le nom de l'album et ...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           sentence  cluster\n",
       "2807    3338  Cher M XXXXXX, CANALSAT lance aujourd'hui une ...     1122\n",
       "3521    4178  Rougui est passé par là: il a fait un gros tra...     1215\n",
       "23173  27182  Attention : \"La BCD\" nécessite que le format d...      126\n",
       "28796  33661  Mon espérence sur ce peut-être nouveau zelda s...      893\n",
       "40245  47148  Sachant que « XXXX » est le nom de l'album et ...      156"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toby Usher\\AppData\\Local\\Temp\\ipykernel_22516\\2782004905.py:2: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df = df[~df['sentence'].str.contains(r'([a-z])\\1\\1\\1', regex=True, na=False, case=False)]\n"
     ]
    }
   ],
   "source": [
    "# Remove these from the dataset\n",
    "df = df[~df['sentence'].str.contains(r'([a-z])\\1\\1\\1', regex=True, na=False, case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove web addresses and emails\n",
    "df = df[~df['sentence'].str.contains(r'www\\.|@|http://|\\\\\\\\|//', regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          638773\n",
       "sentence    638773\n",
       "cluster     638773\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apart from anticonstitutionnellement and a few others, there are effectively no words over 20 letters in french, so any sentences with a string of characters longer than this should probably be removed.\n",
    "# This doesn't account for hyphens and apostrophes but words this long might cause wrapping issues in the app anyway.\n",
    "# 19\n",
    "df = df[~df['sentence'].str.contains(r'\\b\\w{20,}\\b', regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any grammatical weirdness\n",
    "\"\"\"\n",
    "..\n",
    "''\n",
    "\"\"\n",
    "--\n",
    "==\n",
    "->\n",
    "=>\n",
    ":)\n",
    ":-)\n",
    ":(\n",
    "??\n",
    "((\n",
    "))\n",
    "&#\n",
    "\"\"\"\n",
    "df = df[~df['sentence'].str.contains(r'\\.\\.|\\'\\'|\\\"\\\"|--|==|->|=>|:\\)|:-\\)|:\\(|\\?\\?|\\(\\(|\\)\\)|&#', regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          624015\n",
       "sentence    624015\n",
       "cluster     624015\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any sentences that contain three or more unique strings of numbers. This is fairly\n",
    "# restrictive but the dataset is large so I can afford to be picky\n",
    "\n",
    "def count_numbers(sentence):\n",
    "    return len(re.findall(r'\\b\\d+\\b', sentence))\n",
    "\n",
    "# Apply the function to the 'sentence' column\n",
    "df['number_count'] = df['sentence'].apply(count_numbers)\n",
    "\n",
    "# Remove rows where 'number_count' is three or more\n",
    "df = df[df['number_count'] < 3]\n",
    "\n",
    "# Optionally, remove the 'number_count' column\n",
    "df = df.drop(columns=['number_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          583057\n",
       "sentence    583057\n",
       "cluster     583057\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to 100,000 randomly selected sentences with seed\n",
    "#n_rows = 100_000\n",
    "\n",
    "#reduced_df = df.sample(n=n_rows, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space to try new matches\n",
    "#df_filtered = df[df['sentence'].str.contains(r'&#', regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filtered.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove id column and save dataframes as csv\n",
    "df.to_csv(\"./french_sentences_cleaned_with_cluster_labels.csv\", sep='\\t', index=False)\n",
    "\n",
    "#reduced_df.to_csv(\"./reduced_french_sentences_cleaned_with_cluster_labels.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
