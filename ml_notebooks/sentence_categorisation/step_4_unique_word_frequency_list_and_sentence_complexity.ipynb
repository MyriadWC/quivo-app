{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to go through my cleaned word list, split all sentences into their individual words, and create a new dataframe containing each individual word and the number of occurrences within the dataset to determine dataset word frequency (Which I will take as a proxy for overall word frequency). This isn't perfect and will ignore context-defined meaning in words that are spelled the same, as this will be counted as only one highly frequent word with multiple meanings rather than several less-frequent words that are spelled the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few issues will need to be solved here.\n",
    "\n",
    "1. There will be typos and misspellings in the dataset which as well as being less useful as a learning tool, will also lead to some words (particularly those with accents that have been forgotten or misplaced) being counted multiple times, so they'll somehow need to be joined together. I can't just remove all accents as this can change the meaning of a word entirely (côté vs. côte). The approach I took was to just remove any sentences containing the least frequent words and then remove them from the corpus, which will remove a big chunk of typos, but the more common ones could still be in there.\n",
    "\n",
    "2. Words that have been shortened due to consecutive vowels (l, d etc. could have multiple meanings such as le or la, or de or du), but since these are incredibly common words that will always have high scores it might not be so much of an issue for gauging the word's frequency. I just need to make sure to check less frequent words that have been shortened i.e. the presque in presqu'île, although I imagine this shortening would be sufficiently infrequent relative to its unshortened form as to have almost no bearing on its frequency score.\n",
    "\n",
    "3. I might have to set some custom rules for when to keep an apostrophe. Returning to my previous example, presqu'île should really be treated as a single word, and other such exceptions will exist. I just need to go down the frequency list and note them down.\n",
    "\n",
    "4. Different word types will have differing numbers of forms. Adjectives can be masculine or feminine (public, publique), plus others such as publiquement. Verbs can have a very large number of forms, meaning etre is likely to be separated far more than most adjectives which will have fewer forms, which could lead to forms of etre appearing below far less common words in the frequency list. For a language learner these forms can sometimes be similar, allowing a transfer of knowledge when learning new forms (If they know courir it doesn't take much to figure out that couru is just the past tense), while other times the different forms might represent entirely new strings of characters that must all be learnt independently from one another (aller, irai etc.). I'd say that since these are effectively different words that each have to be learned, it is reasonable that they are treated separately. I'm effectively mapping the frequency of different strings of letters appearing in a language.\n",
    "\n",
    "While this method for measuring word frequency is flawed, as long as I ensure that the sentences in my database are grammatically correct it should be useful enough as a tool to gauge sentence complexity via average word frequency, which is the ultimate aim. I could also use POS tagging by running each sentence through a pretrained hidden markov model or something similar to label word type, and have the frequency for each word+type pair. This would avoid the issue of words with multiple meanings being classified together (est for is and east etc.). I have to do this later for the single-word translation to work so it would make sense to do it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some weird caching issue so overriding for now\n",
    "constants.language_code = 'fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f\"../output_files/{constants.language_code}/step3_sentences.csv\"\n",
    "\n",
    "df = pd.read_csv(filepath, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence               135010\n",
       "translated_sentence    135010\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ถ้า', 'คน', 'ของ', 'พวกคุณ', 'จะ', ' ', 'ทำหน้าที่', 'ได้ดี', 'กว่า', 'นี้', ' ', 'คุณ', 'ต้องการ', 'ได้', 'ทำให้', 'แน่ใจ', 'ว่า', ' ', '\\\\', ' ', 'โรคจิต', 'เล็ก', ' ', 'ๆ', ' ', 'น้อย', ' ', 'ๆ', ' ', 'ยัง', 'ต้อง', 'ถูก', 'กักขัง', 'อยู่', ' ', 'หลังจากที่', ' ', 'จับ', 'เรา', 'ทั้งหมด', 'เป็นตัว', 'ประกัน', 'ด้วย', 'ปืน']\n"
     ]
    }
   ],
   "source": [
    "from thai_segmenter import tokenize\n",
    "\n",
    "sentence = \"ถ้าคนของพวกคุณจะ ทำหน้าที่ได้ดีกว่านี้ คุณต้องการได้ทำให้แน่ใจว่า \\ โรคจิตเล็ก ๆ น้อย ๆ ยังต้องถูกกักขังอยู่ หลังจากที่ จับเราทั้งหมดเป็นตัวประกันด้วยปืน\"\n",
    "tokens = tokenize(sentence)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regex\n",
    "\n",
    "fr_exceptions = [\n",
    "    \"[Aa]ujourd'hui\",\n",
    "    \"[Pp]resqu'île\",\n",
    "    \"[Qq]uelqu'un\",\n",
    "    \"[Dd]'accord\"\n",
    "    ]\n",
    "\n",
    "de_exceptions = []\n",
    "ru_exceptions = []\n",
    "\n",
    "exceptions = {\n",
    "    'fr': fr_exceptions,\n",
    "    'de': de_exceptions,\n",
    "    'ru': ru_exceptions,\n",
    "    'th': ''\n",
    "    }[constants.language_code]\n",
    "\n",
    "word_regex = {\n",
    "    'fr': r'[a-zA-ZéèêëÉÈÊËàâäÀÂÄôöÔÖûüùÛÜÙçÇîÎïÏ]+',\n",
    "    'de': r'[a-zA-ZäöüÄÖÜß]+',\n",
    "    'ru': r'[А-Яа-яЁё]+',\n",
    "    'th': ''\n",
    "    }[constants.language_code]\n",
    "\n",
    "exceptions_regex = '|'.join(exceptions)\n",
    "\n",
    "# Not ideal but de empty exceptions was causing issues\n",
    "regex = {\n",
    "    'fr': fr'\\b{exceptions_regex}|{word_regex}\\b',\n",
    "    'de': fr'\\b{word_regex}\\b',\n",
    "    'ru': fr'\\b{word_regex}\\b',\n",
    "    'th': ''\n",
    "    }[constants.language_code]\n",
    "\n",
    "# Separates and keeps all sentence components, not just words\n",
    "# Want to match into one of two categories: valid words and everything else\n",
    "inclusive_regex = {\n",
    "    'fr': r'/(?:[Aa]ujourd\\'hui|[Pp]resqu\\'île|[Qq]uelqu\\'un|[Dd]\\'accord|-t-|[a-zA-Z0-9éèêëÉÈÊËàâäÀÂÄôöÔÖûüùÛÜÙçÇîÎïÏ]+|[^a-zA-Z0-9éèêëÉÈÊËàâäÀÂÄôöÔÖûüùÛÜÙçÇîÎïÏ]+)/g',\n",
    "    'de': r'/(?:[a-zA-ZäöüÄÖÜß]+|[^a-zA-ZäöüÄÖÜß])/g',\n",
    "    'ru': r'/(?:[А-Яа-яЁё]+|[^А-Яа-яЁё])/g',\n",
    "    }[constants.language_code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened_word_map = {\n",
    "    'j': 'je',\n",
    "    #'l': 'le', # Can be either so will handle after to speed up function\n",
    "    't': 'tu', # This will assign the t in a-t-on to tu for example, which will give tu a higher frequency than it should have, but it's only one very common word so I'm not going to address it\n",
    "    'd': 'de', # Need to check whether this is ever du\n",
    "    'c': 'ce',\n",
    "    's': 'se',\n",
    "    'qu': 'que',\n",
    "    'm': 'me',\n",
    "    'n': 'ne',\n",
    "    }\n",
    "\n",
    "def scan_sentence(sentence: str, unique_word_counts: defaultdict) -> defaultdict:\n",
    "    '''Scans a sentence to get its words and updates the unique word count dictionary.\n",
    "    Local unique_word_counts points to global variable so can update directly. The use\n",
    "    of a default dict means we don't have to check if a key is in the dictionary before\n",
    "    adding it as it will initialise to 1.\n",
    "\n",
    "    Using a dict instead of a dataframe means there's O(1) time complexity for insertions\n",
    "    and lookups, and using a defaultdict to avoid an additional check means this runs\n",
    "    incredibly quickly on even very large datasets.\n",
    "    '''\n",
    "\n",
    "    # Split all words in the sentence by word boundaries (Split uninclusively at punctuation or non-alphanumeric characters)\n",
    "    if constants.language_code == 'th':\n",
    "        words = tokenize(sentence)\n",
    "    else:\n",
    "        words = re.findall(regex, sentence) # Words only\n",
    "\n",
    "    # Set all words to lowercase\n",
    "    words = [word.lower() for word in words]\n",
    "\n",
    "    # Replace any shortened words with their full-length version\n",
    "    if constants.language_code == 'fr':\n",
    "        words = [shortened_word_map.get(word, word) for word in words]\n",
    "\n",
    "    for word in words:\n",
    "\n",
    "        # Add 1 to count. If word doesn't exist adds in new entry\n",
    "        unique_word_counts[word] += 1\n",
    "\n",
    "    return unique_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>translated_sentence</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pour une fois dans ma vie je fais un bon geste...</td>\n",
       "      <td>For once in my life I'm doing a good deed... A...</td>\n",
       "      <td>[pour, une, fois, dans, ma, vie, je, fais, un,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Je ne sais simplement pas quoi dire...</td>\n",
       "      <td>I just don't know what to say.</td>\n",
       "      <td>[je, ne, sais, simplement, pas, quoi, dire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tout le monde doit apprendre par soi-même en f...</td>\n",
       "      <td>Everyone must learn on their own in the end.</td>\n",
       "      <td>[tout, le, monde, doit, apprendre, par, soi, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L'apprentissage ne devrait pas être forcé. L'a...</td>\n",
       "      <td>Learning should not be forced. Learning should...</td>\n",
       "      <td>[l, apprentissage, ne, devrait, pas, être, for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parfois il peut être un gars bizarre.</td>\n",
       "      <td>Sometimes he can be a strange guy.</td>\n",
       "      <td>[parfois, il, peut, être, un, gars, bizarre]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  Pour une fois dans ma vie je fais un bon geste...   \n",
       "1             Je ne sais simplement pas quoi dire...   \n",
       "2  Tout le monde doit apprendre par soi-même en f...   \n",
       "3  L'apprentissage ne devrait pas être forcé. L'a...   \n",
       "4              Parfois il peut être un gars bizarre.   \n",
       "\n",
       "                                 translated_sentence  \\\n",
       "0  For once in my life I'm doing a good deed... A...   \n",
       "1                     I just don't know what to say.   \n",
       "2       Everyone must learn on their own in the end.   \n",
       "3  Learning should not be forced. Learning should...   \n",
       "4                 Sometimes he can be a strange guy.   \n",
       "\n",
       "                                               words  \n",
       "0  [pour, une, fois, dans, ma, vie, je, fais, un,...  \n",
       "1        [je, ne, sais, simplement, pas, quoi, dire]  \n",
       "2  [tout, le, monde, doit, apprendre, par, soi, m...  \n",
       "3  [l, apprentissage, ne, devrait, pas, être, for...  \n",
       "4       [parfois, il, peut, être, un, gars, bizarre]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word         32197\n",
      "frequency    32197\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#unique_word_counts = pd.DataFrame(columns=['word', 'count'])\n",
    "unique_word_counts_dict = defaultdict(int)\n",
    "\n",
    "for sentence in df['sentence'].values:\n",
    "\n",
    "    #unique_word_counts = scan_sentence(sentence, unique_word_counts)\n",
    "    unique_word_counts_dict = scan_sentence(sentence, unique_word_counts_dict)\n",
    "\n",
    "# Convert the dictionary to a list of tuples\n",
    "unique_word_counts = list(unique_word_counts_dict.items())\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "unique_word_counts = pd.DataFrame(unique_word_counts, columns=['word', 'frequency'])\n",
    "\n",
    "print(unique_word_counts.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toby Usher\\AppData\\Local\\Temp\\ipykernel_8696\\2358905942.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[28571.4]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  unique_word_counts.loc[unique_word_counts['word'] == 'le', 'frequency'] += l_count * le_frequency\n"
     ]
    }
   ],
   "source": [
    "# Need to distribute l appropriately between le and la counts. Based off my previous counts la occurs\n",
    "# 55% of the time\n",
    "if (constants.language_code == 'fr'):\n",
    "\n",
    "    le_frequency = 0.45\n",
    "\n",
    "    l_count = unique_word_counts[unique_word_counts['word'] == 'l']['frequency'].values[0]\n",
    "\n",
    "    unique_word_counts.loc[unique_word_counts['word'] == 'le', 'frequency'] += l_count * le_frequency\n",
    "    unique_word_counts.loc[unique_word_counts['word'] == 'la','frequency'] += l_count * (1 - le_frequency)\n",
    "\n",
    "    # Remove l row\n",
    "    unique_word_counts = unique_word_counts.drop(\n",
    "        unique_word_counts[unique_word_counts['word'] == 'l'].index\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# A parallel approach to creating the unique word counts. A single process is sufficient anyway\\n\\nimport numpy as np\\nimport multiprocessing\\n\\n# check how many cores are available\\nnum_cpus = multiprocessing.cpu_count()\\n\\nnum_chunks = 4\\n\\nif num_cpus < num_chunks:\\n    raise SystemError(f'Insufficient number of CPUs ({num_cpus}) for chosen number of chunks ({num_chunks})')\\n\\n# split dataset into chunks\\nchunks = np.array_split(df, num_chunks)\\n\\n# Define the function to be run in each process\\ndef count_words_chunk(chunk: pd.DataFrame, unique_word_counts: defaultdict):\\n    '''Calculates the unique word counts for a given chunk of the sentences\\n    '''\\n\\n    # Perform your operations on the chunk here\\n    # For example, compute the mean of each column\\n    for sentence in chunk['sentence'].values:\\n\\n        unique_word_counts = scan_sentence(sentence, unique_word_counts)\\n\\n    return unique_word_counts\\n\\nunique_word_counts_dict_multiprocessing = defaultdict(int)\\n\\n# Create a pool of processes\\nwith multiprocessing.Pool(num_chunks) as p:\\n    # Apply the function to each chunk in the pool of processes\\n    #results = p.map(count_words_chunk, chunks, unique_word_counts_dict_multiprocessing)\\n    results = p.starmap(count_words_chunk, [(chunk, unique_word_counts_dict_multiprocessing) for chunk in chunks])\\n\\nunique_word_counts_dict = {}\\n\\n# Now 'results' is a list of the results from each process\\nfor i, chunk_unique_word_counts in enumerate(results):\\n    # Combine the unique word count dataframes from each process into one and save\\n    unique_word_counts_dict = unique_word_counts_dict | chunk_unique_word_counts\\n\\n# Convert the dictionary to a list of tuples\\nunique_word_counts = list(unique_word_counts_dict.items())\\n\\n# Convert the list to a DataFrame\\nunique_word_counts = pd.DataFrame(unique_word_counts, columns=['word', 'count'])\\n\\nprint(unique_word_counts.count())\\n\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# A parallel approach to creating the unique word counts. A single process is sufficient anyway\n",
    "\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "# check how many cores are available\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "num_chunks = 4\n",
    "\n",
    "if num_cpus < num_chunks:\n",
    "    raise SystemError(f'Insufficient number of CPUs ({num_cpus}) for chosen number of chunks ({num_chunks})')\n",
    "\n",
    "# split dataset into chunks\n",
    "chunks = np.array_split(df, num_chunks)\n",
    "\n",
    "# Define the function to be run in each process\n",
    "def count_words_chunk(chunk: pd.DataFrame, unique_word_counts: defaultdict):\n",
    "    '''Calculates the unique word counts for a given chunk of the sentences\n",
    "    '''\n",
    "\n",
    "    # Perform your operations on the chunk here\n",
    "    # For example, compute the mean of each column\n",
    "    for sentence in chunk['sentence'].values:\n",
    "\n",
    "        unique_word_counts = scan_sentence(sentence, unique_word_counts)\n",
    "\n",
    "    return unique_word_counts\n",
    "\n",
    "unique_word_counts_dict_multiprocessing = defaultdict(int)\n",
    "\n",
    "# Create a pool of processes\n",
    "with multiprocessing.Pool(num_chunks) as p:\n",
    "    # Apply the function to each chunk in the pool of processes\n",
    "    #results = p.map(count_words_chunk, chunks, unique_word_counts_dict_multiprocessing)\n",
    "    results = p.starmap(count_words_chunk, [(chunk, unique_word_counts_dict_multiprocessing) for chunk in chunks])\n",
    "\n",
    "unique_word_counts_dict = {}\n",
    "\n",
    "# Now 'results' is a list of the results from each process\n",
    "for i, chunk_unique_word_counts in enumerate(results):\n",
    "    # Combine the unique word count dataframes from each process into one and save\n",
    "    unique_word_counts_dict = unique_word_counts_dict | chunk_unique_word_counts\n",
    "\n",
    "# Convert the dictionary to a list of tuples\n",
    "unique_word_counts = list(unique_word_counts_dict.items())\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "unique_word_counts = pd.DataFrame(unique_word_counts, columns=['word', 'count'])\n",
    "\n",
    "print(unique_word_counts.count())\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having looked at the dataset, most words that appear three times or fewer in the dataset are either typos or\n",
    "sufficiently obscure that I should probably remove any sentences that contain these words. The logarithmic\n",
    "nature of word frequency distributions in a text corpus means this will cause the number of unique words in\n",
    "the corpus to drop significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32097</th>\n",
       "      <td>cadienne</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32098</th>\n",
       "      <td>cajuns</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32099</th>\n",
       "      <td>cadiens</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32100</th>\n",
       "      <td>fonçait</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32101</th>\n",
       "      <td>liguer</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32192</th>\n",
       "      <td>torpilles</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32193</th>\n",
       "      <td>orale</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32194</th>\n",
       "      <td>végéter</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32195</th>\n",
       "      <td>augmentant</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32196</th>\n",
       "      <td>coexister</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  frequency\n",
       "32097    cadienne        1.0\n",
       "32098      cajuns        1.0\n",
       "32099     cadiens        1.0\n",
       "32100     fonçait        1.0\n",
       "32101      liguer        1.0\n",
       "...           ...        ...\n",
       "32192   torpilles        1.0\n",
       "32193       orale        1.0\n",
       "32194     végéter        1.0\n",
       "32195  augmentant        1.0\n",
       "32196   coexister        1.0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_word_counts.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of times a word has to appear in the corpus for it to be kept\n",
    "obscurity_cutoff = 1\n",
    "\n",
    "# Get list of words that occur less than this in the dataset\n",
    "obscure_words = unique_word_counts[unique_word_counts['frequency'] < obscurity_cutoff]['word'].to_list()\n",
    "\n",
    "# Convert the list of words to a set for faster lookup\n",
    "obscure_words = set(obscure_words)\n",
    "\n",
    "# Split the sentences into words (Must use the same regex as was used to create the original word frequency list)\n",
    "if constants.language_code == 'th':\n",
    "    df['words'] = df['sentence'].apply(lambda x: tokenize(x))\n",
    "    df['split_sentence'] = df ['words']\n",
    "else:\n",
    "    df['words'] = df['sentence'].apply(lambda x: re.findall(regex, x.lower()))\n",
    "    df['split_sentence'] = df['sentence'].apply(lambda x: re.findall(inclusive_regex, x))\n",
    "    \n",
    "\n",
    "# Remove any rows where the sentence contains one of the obscure words\n",
    "df = df[~df['words'].apply(lambda x: any(word in obscure_words for word in x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence               135010\n",
       "translated_sentence    135010\n",
       "words                  135010\n",
       "split_sentence         135010\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has removed hundreds of thousands of sentences from the dataset and drastically reduced the number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>translated_sentence</th>\n",
       "      <th>words</th>\n",
       "      <th>split_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pour une fois dans ma vie je fais un bon geste...</td>\n",
       "      <td>For once in my life I'm doing a good deed... A...</td>\n",
       "      <td>[pour, une, fois, dans, ma, vie, je, fais, un,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Je ne sais simplement pas quoi dire...</td>\n",
       "      <td>I just don't know what to say.</td>\n",
       "      <td>[je, ne, sais, simplement, pas, quoi, dire]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tout le monde doit apprendre par soi-même en f...</td>\n",
       "      <td>Everyone must learn on their own in the end.</td>\n",
       "      <td>[tout, le, monde, doit, apprendre, par, soi, m...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L'apprentissage ne devrait pas être forcé. L'a...</td>\n",
       "      <td>Learning should not be forced. Learning should...</td>\n",
       "      <td>[l, apprentissage, ne, devrait, pas, être, for...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parfois il peut être un gars bizarre.</td>\n",
       "      <td>Sometimes he can be a strange guy.</td>\n",
       "      <td>[parfois, il, peut, être, un, gars, bizarre]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  Pour une fois dans ma vie je fais un bon geste...   \n",
       "1             Je ne sais simplement pas quoi dire...   \n",
       "2  Tout le monde doit apprendre par soi-même en f...   \n",
       "3  L'apprentissage ne devrait pas être forcé. L'a...   \n",
       "4              Parfois il peut être un gars bizarre.   \n",
       "\n",
       "                                 translated_sentence  \\\n",
       "0  For once in my life I'm doing a good deed... A...   \n",
       "1                     I just don't know what to say.   \n",
       "2       Everyone must learn on their own in the end.   \n",
       "3  Learning should not be forced. Learning should...   \n",
       "4                 Sometimes he can be a strange guy.   \n",
       "\n",
       "                                               words split_sentence  \n",
       "0  [pour, une, fois, dans, ma, vie, je, fais, un,...             []  \n",
       "1        [je, ne, sais, simplement, pas, quoi, dire]             []  \n",
       "2  [tout, le, monde, doit, apprendre, par, soi, m...             []  \n",
       "3  [l, apprentissage, ne, devrait, pas, être, for...             []  \n",
       "4       [parfois, il, peut, être, un, gars, bizarre]             []  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Table, MetaData\n",
    "\n",
    "# Remove the obscure words from the word counts dataframe and save new dataset and word counts\n",
    "unique_word_counts = unique_word_counts[unique_word_counts['frequency'] >= obscurity_cutoff]\n",
    "\n",
    "# Remove NaN\n",
    "unique_words_counts = unique_word_counts[unique_word_counts['word'].isna()]\n",
    "\n",
    "# Sort and save the frequency list into final tables\n",
    "sorted_word_counts = unique_word_counts.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "#sorted_word_counts['rank'] = sorted_word_counts['frequency'].rank(ascending=False)\n",
    "\n",
    "# Reset the index\n",
    "sorted_word_counts = sorted_word_counts.reset_index(drop=True)\n",
    "\n",
    "sorted_word_counts['rank'] = sorted_word_counts.index + 1\n",
    "\n",
    "sorted_word_counts = sorted_word_counts[['rank', 'word', 'frequency']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of         rank           word  frequency\n",
       "0          1             de    49863.0\n",
       "1          2             je    37991.0\n",
       "2          3             la    32012.6\n",
       "3          4             le    28571.4\n",
       "4          5            que    28236.0\n",
       "...      ...            ...        ...\n",
       "32191  32192  antiatomiques        1.0\n",
       "32192  32193       suicides        1.0\n",
       "32193  32194        seppuku        1.0\n",
       "32194  32195  désamorcèrent        1.0\n",
       "32195  32196      coexister        1.0\n",
       "\n",
       "[32196 rows x 3 columns]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_word_counts.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Primarily IO bound so shouldn't be running serially. Need to\n",
    "# make asynchronous.\n",
    "\n",
    "# Get translation for each word using libretranslate\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from libretranslatepy import LibreTranslateAPI\n",
    "\n",
    "# Initialize the LibreTranslate API\n",
    "#lt = LibreTranslateAPI('https://translate.astian.org/translate')\n",
    "lt = LibreTranslateAPI('http://localhost:5000')\n",
    "\n",
    "def translate_word(word):\n",
    "    try:\n",
    "        translation = lt.translate(word, constants.language_code, 'en')\n",
    "        return translation\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating word {word}: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        sorted_word_counts['translation'] = list(executor.map(translate_word, sorted_word_counts['word']))\n",
    "\n",
    "main()\n",
    "\n",
    "#sorted_word_counts['translation'] = sorted_word_counts['word'].apply(translate_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       rank        word  frequency   translation\n",
       "0        1         ฉัน       1005           I..\n",
       "1        2         คุณ        800           You\n",
       "2        3         ทอม        513           Tom\n",
       "3        4          ผม        465           I..\n",
       "4        5         ของ        431        Things\n",
       "...    ...         ...        ...           ...\n",
       "2676  2677  เด็กกำพร้า          1     An orphan\n",
       "2677  2678   กฎระเบียบ          1         Rules\n",
       "2678  2679       หน้อย          1        Little\n",
       "2679  2680         ชัา          1           Shh\n",
       "2680  2681   ใกล้เคียง          1  Close enough\n",
       "\n",
       "[2681 rows x 4 columns]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_word_counts.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns to match model\n",
    "sorted_word_counts = sorted_word_counts[[\n",
    "    'rank',\n",
    "    'word',\n",
    "    'translation',\n",
    "    'frequency'\n",
    "    ]]\n",
    "\n",
    "# Save to CSV\n",
    "sorted_word_counts.to_csv(f'../output_files/{constants.language_code}/step4_unique_word_counts.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to update the words database without removing existing many-to-many relationships on words that still exist in the\n",
    "# new corpus\n",
    "\n",
    "from sqlalchemy import create_engine, text, MetaData, Table\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.sql import select\n",
    "\n",
    "# Create engine\n",
    "engine = create_engine('postgresql://quivo_default:s567tyug328726hj9j83@localhost:5432/quivo')\n",
    "\n",
    "# Update table in sqlalchemy------------------------------------\n",
    "\n",
    "# Note that you first have to delete the many to many 'words_known' relationship between\n",
    "# users and the word data, so use with caution.\n",
    "\n",
    "# Now update the word data table with the new unique words\n",
    "#conn = engine.connect()\n",
    "#conn.execute(text(f'DROP TABLE language_app_deworddata CASCADE'))\n",
    "#conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "(psycopg2.errors.DependentObjectsStillExist) cannot drop table language_app_thworddata because other objects depend on it\nDETAIL:  constraint api_userword_word_th_id_3e82f22f_fk_language_app_thworddata_id on table api_userword depends on table language_app_thworddata\nHINT:  Use DROP ... CASCADE to drop the dependent objects too.\n\n[SQL: \nDROP TABLE language_app_thworddata]\n(Background on this error at: https://sqlalche.me/e/20/2j85)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDependentObjectsStillExist\u001b[0m                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1969\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1969\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1970\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:922\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 922\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mDependentObjectsStillExist\u001b[0m: cannot drop table language_app_thworddata because other objects depend on it\nDETAIL:  constraint api_userword_word_th_id_3e82f22f_fk_language_app_thworddata_id on table api_userword depends on table language_app_thworddata\nHINT:  Use DROP ... CASCADE to drop the dependent objects too.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msorted_word_counts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlanguage_app_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlanguage_code\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mworddata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreplace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:3008\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2813\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2814\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2815\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3004\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   3005\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3006\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[1;32m-> 3008\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3009\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3012\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\pandas\\io\\sql.py:788\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    785\u001b[0m     )\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\pandas\\io\\sql.py:1948\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1898\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   1900\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1944\u001b[0m \u001b[38;5;124;03m    Any additional kwargs are passed to the engine.\u001b[39;00m\n\u001b[0;32m   1945\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1946\u001b[0m sql_engine \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[1;32m-> 1948\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1956\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1958\u001b[0m total_inserted \u001b[38;5;241m=\u001b[39m sql_engine\u001b[38;5;241m.\u001b[39minsert_records(\n\u001b[0;32m   1959\u001b[0m     table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m   1960\u001b[0m     con\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1967\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m   1968\u001b[0m )\n\u001b[0;32m   1970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_case_sensitive(name\u001b[38;5;241m=\u001b[39mname, schema\u001b[38;5;241m=\u001b[39mschema)\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\pandas\\io\\sql.py:1852\u001b[0m, in \u001b[0;36mSQLDatabase.prep_table\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, dtype)\u001b[0m\n\u001b[0;32m   1840\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe type of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a SQLAlchemy type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1842\u001b[0m table \u001b[38;5;241m=\u001b[39m SQLTable(\n\u001b[0;32m   1843\u001b[0m     name,\n\u001b[0;32m   1844\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1850\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1851\u001b[0m )\n\u001b[1;32m-> 1852\u001b[0m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1853\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\pandas\\io\\sql.py:929\u001b[0m, in \u001b[0;36mSQLTable.create\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 929\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpd_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_create()\n\u001b[0;32m    931\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\pandas\\io\\sql.py:2003\u001b[0m, in \u001b[0;36mSQLDatabase.drop_table\u001b[1;34m(self, table_name, schema)\u001b[0m\n\u001b[0;32m   1999\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mreflect(\n\u001b[0;32m   2000\u001b[0m     bind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon, only\u001b[38;5;241m=\u001b[39m[table_name], schema\u001b[38;5;241m=\u001b[39mschema, views\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2001\u001b[0m )\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_transaction():\n\u001b[1;32m-> 2003\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\sqlalchemy\\sql\\schema.py:1305\u001b[0m, in \u001b[0;36mTable.drop\u001b[1;34m(self, bind, checkfirst)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\u001b[38;5;28mself\u001b[39m, bind: _CreateDropBind, checkfirst: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Issue a ``DROP`` statement for this\u001b[39;00m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;124;03m    :class:`_schema.Table`, using the given\u001b[39;00m\n\u001b[0;32m   1298\u001b[0m \u001b[38;5;124;03m    :class:`.Connection` or :class:`.Engine` for connectivity.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1303\u001b[0m \n\u001b[0;32m   1304\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[43mbind\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_ddl_visitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mddl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSchemaDropper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckfirst\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2447\u001b[0m, in \u001b[0;36mConnection._run_ddl_visitor\u001b[1;34m(self, visitorcallable, element, **kwargs)\u001b[0m\n\u001b[0;32m   2435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_ddl_visitor\u001b[39m(\n\u001b[0;32m   2436\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2437\u001b[0m     visitorcallable: Type[Union[SchemaGenerator, SchemaDropper]],\n\u001b[0;32m   2438\u001b[0m     element: SchemaItem,\n\u001b[0;32m   2439\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   2440\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2441\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"run a DDL visitor.\u001b[39;00m\n\u001b[0;32m   2442\u001b[0m \n\u001b[0;32m   2443\u001b[0m \u001b[38;5;124;03m    This method is only here so that the MockConnection can change the\u001b[39;00m\n\u001b[0;32m   2444\u001b[0m \u001b[38;5;124;03m    options given to the visitor so that \"checkfirst\" is skipped.\u001b[39;00m\n\u001b[0;32m   2445\u001b[0m \n\u001b[0;32m   2446\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2447\u001b[0m     \u001b[43mvisitorcallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraverse_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\sqlalchemy\\sql\\visitors.py:671\u001b[0m, in \u001b[0;36mExternalTraversal.traverse_single\u001b[1;34m(self, obj, **kw)\u001b[0m\n\u001b[0;32m    669\u001b[0m meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(v, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m obj\u001b[38;5;241m.\u001b[39m__visit_name__, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meth:\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\sqlalchemy\\sql\\ddl.py:1142\u001b[0m, in \u001b[0;36mSchemaDropper.visit_table\u001b[1;34m(self, table, drop_ok, _is_metadata_operation, _ignore_sequences)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_ddl_events(\n\u001b[0;32m   1138\u001b[0m     table,\n\u001b[0;32m   1139\u001b[0m     checkfirst\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckfirst,\n\u001b[0;32m   1140\u001b[0m     _is_metadata_operation\u001b[38;5;241m=\u001b[39m_is_metadata_operation,\n\u001b[0;32m   1141\u001b[0m ):\n\u001b[1;32m-> 1142\u001b[0m     \u001b[43mDropTable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_with\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# traverse client side defaults which may refer to server-side\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m# sequences. noting that some of these client side defaults may\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;66;03m# also be set up as server side defaults\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;66;03m# #associating-a-sequence-as-the-server-side-\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m     \u001b[38;5;66;03m# default), so have to be dropped after the table is dropped.\u001b[39;00m\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\sqlalchemy\\sql\\ddl.py:315\u001b[0m, in \u001b[0;36mExecutableDDLElement._invoke_with\u001b[1;34m(self, bind)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_invoke_with\u001b[39m(\u001b[38;5;28mself\u001b[39m, bind):\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_execute(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget, bind):\n\u001b[1;32m--> 315\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbind\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1416\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1417\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\sqlalchemy\\sql\\ddl.py:181\u001b[0m, in \u001b[0;36mExecutableDDLElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_on_connection\u001b[39m(\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m, connection, distilled_params, execution_options\n\u001b[0;32m    180\u001b[0m ):\n\u001b[1;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_ddl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1528\u001b[0m, in \u001b[0;36mConnection._execute_ddl\u001b[1;34m(self, ddl, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1523\u001b[0m dialect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\n\u001b[0;32m   1525\u001b[0m compiled \u001b[38;5;241m=\u001b[39m ddl\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m   1526\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect, schema_translate_map\u001b[38;5;241m=\u001b[39mschema_translate_map\n\u001b[0;32m   1527\u001b[0m )\n\u001b[1;32m-> 1528\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_ddl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[0;32m   1538\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1539\u001b[0m         ddl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1543\u001b[0m         ret,\n\u001b[0;32m   1544\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1848\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(\n\u001b[0;32m   1844\u001b[0m         dialect,\n\u001b[0;32m   1845\u001b[0m         context,\n\u001b[0;32m   1846\u001b[0m     )\n\u001b[0;32m   1847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[0;32m   1850\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1988\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1985\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[0;32m   1987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1988\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1989\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1990\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2343\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2341\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2342\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2343\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2345\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1969\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1967\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1969\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1970\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[0;32m   1974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1975\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1976\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1980\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[0;32m   1981\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Toby Usher\\Documents\\dev\\quivo-app\\venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:922\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 922\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: (psycopg2.errors.DependentObjectsStillExist) cannot drop table language_app_thworddata because other objects depend on it\nDETAIL:  constraint api_userword_word_th_id_3e82f22f_fk_language_app_thworddata_id on table api_userword depends on table language_app_thworddata\nHINT:  Use DROP ... CASCADE to drop the dependent objects too.\n\n[SQL: \nDROP TABLE language_app_thworddata]\n(Background on this error at: https://sqlalche.me/e/20/2j85)"
     ]
    }
   ],
   "source": [
    "sorted_word_counts.to_sql(f'language_app_{constants.language_code}worddata', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Create a Session\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Reflect table\n",
    "metadata = MetaData()\n",
    "words_table = Table(f'language_app_{constants.language_code}worddata', metadata, autoload_with=engine)\n",
    "\n",
    "# Loop through each word in the dataframe\n",
    "for index, row in sorted_word_counts.iterrows():\n",
    "    word = row['word']  # assuming 'word' is the column name in your dataframe\n",
    "    # Check if it already exists in the database\n",
    "    stmt = select(words_table).where(words_table.c.word == word)  # assuming 'word' is the column name in your table\n",
    "    result = session.execute(stmt).fetchone()\n",
    "    if result:\n",
    "        # If it does, update the record but don't delete it\n",
    "        row_dict = row.to_dict()\n",
    "        row_dict.pop('id', None)\n",
    "        update_stmt = (\n",
    "            words_table.update().\n",
    "            where(words_table.c.word == word).\n",
    "            values(**row.to_dict())\n",
    "        )\n",
    "        session.execute(update_stmt)\n",
    "    else:\n",
    "        # If it doesn't, add a new record\n",
    "        insert_stmt = words_table.insert().values(**row_dict)\n",
    "        session.execute(insert_stmt)\n",
    "\n",
    "# Commit the changes\n",
    "session.commit()\n",
    "\n",
    "# Delete all words in the database that don't exist in the new dataframe\n",
    "stmt = (\n",
    "    words_table.delete().\n",
    "    where(words_table.c.word.notin_(sorted_word_counts['word'].tolist()))\n",
    ")\n",
    "session.execute(stmt)\n",
    "\n",
    "# Commit the changes\n",
    "session.commit()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Keep every 100th value for quicker plotting\n",
    "#sorted_word_counts[sorted_word_counts['frequency'] > 1]['frequency'].plot(kind='bar')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating word frequency-based sentence complexity scores\n",
    "\n",
    "Now we know all word frequencies, this information can be used to figure out the average sentence complexity of words within each sentence to get a preliminary idea of which sentences will be more difficult to understand / more or less useful for a language learner at any given level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toby Usher\\AppData\\Local\\Temp\\ipykernel_5040\\3641391163.py:18: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n",
      "  df[['average_count', 'min_count']] = df['words'].apply(calculate_average_and_min, args=(unique_word_counts_dict,))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Use the original word counts dict (Still contains the obscure words but should still be quicker)\n",
    "# to calculate the average and min word counts for each sentence\n",
    "\n",
    "def calculate_average_and_min(row, word_counts):\n",
    "\n",
    "    # Gets all counts for the sentence. Defaults to zero if word missing although this should\n",
    "    # never happen\n",
    "    counts = [word_counts.get(word, 0) for word in row]\n",
    "\n",
    "    if not counts:\n",
    "        return pd.Series([0, 0])\n",
    "    \n",
    "    return pd.Series([np.mean(counts), np.min(counts)])\n",
    "\n",
    "# Mean of all word count frequencies, minimum word frequency (rarest word) in sentence\n",
    "df[['average_count', 'min_count']] = df['words'].apply(calculate_average_and_min, args=(unique_word_counts_dict,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rank columns for average and min counts\n",
    "df['average_count_rank'] = df['average_count'].rank(ascending=True)\n",
    "df['min_count_rank'] = df['min_count'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cluster' not in df.columns:\n",
    "    df['cluster'] = 0\n",
    "\n",
    "# Add in placeholder for translation for now\n",
    "#df['translated_sentence'] = 'Translation'\n",
    "\n",
    "# Remove any translations with a tab in\n",
    "df['translated_sentence'] = df['translated_sentence'].str.replace(r'.*\\t.*', '', regex=True)\n",
    "\n",
    "# Put the dataframe in the correct format for the Django model\n",
    "df = df[[\n",
    "    'sentence',\n",
    "    'split_sentence',\n",
    "    'translated_sentence',\n",
    "    'cluster',\n",
    "    'words',\n",
    "    'average_count',\n",
    "    'min_count',\n",
    "    'average_count_rank',\n",
    "    'min_count_rank'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import sqlalchemy\n",
    "\n",
    "ordered_df = df.sort_values(by='min_count', ascending=True)\n",
    "ordered_df.to_csv(f'../output_files/{constants.language_code}/step4_sentences.csv', sep='\\t')\n",
    "\n",
    "ordered_df.to_sql(\n",
    "    f'language_app_{constants.language_code}sentence',\n",
    "    engine,\n",
    "    if_exists='replace',\n",
    "    dtype={'words': sqlalchemy.types.JSON})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>split_sentence</th>\n",
       "      <th>translated_sentence</th>\n",
       "      <th>cluster</th>\n",
       "      <th>words</th>\n",
       "      <th>average_count</th>\n",
       "      <th>min_count</th>\n",
       "      <th>average_count_rank</th>\n",
       "      <th>min_count_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>มีร้านขายยาในบริเวณใกล้เคียงไหม?</td>\n",
       "      <td>[มี, ร้านขายยา, ใน, บริเวณ, ใกล้เคียง, ไหม, ?]</td>\n",
       "      <td>Is there a pharmacy nearby?</td>\n",
       "      <td>0</td>\n",
       "      <td>[มี, ร้านขายยา, ใน, บริเวณ, ใกล้เคียง, ไหม, ?]</td>\n",
       "      <td>147.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1287.0</td>\n",
       "      <td>2924.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>กล่องหนักเกินกว่าที่จะแบก</td>\n",
       "      <td>[กล่อง, หนัก, เกิน, กว่า, ที่จะ, แบก]</td>\n",
       "      <td>The box is too heavy to carry.</td>\n",
       "      <td>0</td>\n",
       "      <td>[กล่อง, หนัก, เกิน, กว่า, ที่จะ, แบก]</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2924.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>หนังสือเล่มนี้ขายดีในญี่ปุ่น</td>\n",
       "      <td>[หนังสือ, เล่ม, นี้, ขายดี, ใน, ญี่ปุ่น]</td>\n",
       "      <td>This book sold well in Japan.</td>\n",
       "      <td>0</td>\n",
       "      <td>[หนังสือ, เล่ม, นี้, ขายดี, ใน, ญี่ปุ่น]</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>586.0</td>\n",
       "      <td>2924.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>ตำรวจกุมตัวเขาเพราะเมาแล้วขับ</td>\n",
       "      <td>[ตำรวจ, กุม, ตัว, เขา, เพราะ, เมา, แล้ว, ขับ]</td>\n",
       "      <td>The policeman arrested him for drunken driving.</td>\n",
       "      <td>0</td>\n",
       "      <td>[ตำรวจ, กุม, ตัว, เขา, เพราะ, เมา, แล้ว, ขับ]</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>2924.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>ทอมบอกรหัสผ่านเขากับคุณหรือเปล่า</td>\n",
       "      <td>[ทอม, บอก, รหัสผ่าน, เขา, กับ, คุณ, หรือเปล่า]</td>\n",
       "      <td>Did Tom tell you his password?</td>\n",
       "      <td>0</td>\n",
       "      <td>[ทอม, บอก, รหัสผ่าน, เขา, กับ, คุณ, หรือเปล่า]</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2571.0</td>\n",
       "      <td>2924.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sentence  \\\n",
       "3421  มีร้านขายยาในบริเวณใกล้เคียงไหม?   \n",
       "798          กล่องหนักเกินกว่าที่จะแบก   \n",
       "2264      หนังสือเล่มนี้ขายดีในญี่ปุ่น   \n",
       "802      ตำรวจกุมตัวเขาเพราะเมาแล้วขับ   \n",
       "2260  ทอมบอกรหัสผ่านเขากับคุณหรือเปล่า   \n",
       "\n",
       "                                      split_sentence  \\\n",
       "3421  [มี, ร้านขายยา, ใน, บริเวณ, ใกล้เคียง, ไหม, ?]   \n",
       "798            [กล่อง, หนัก, เกิน, กว่า, ที่จะ, แบก]   \n",
       "2264        [หนังสือ, เล่ม, นี้, ขายดี, ใน, ญี่ปุ่น]   \n",
       "802    [ตำรวจ, กุม, ตัว, เขา, เพราะ, เมา, แล้ว, ขับ]   \n",
       "2260  [ทอม, บอก, รหัสผ่าน, เขา, กับ, คุณ, หรือเปล่า]   \n",
       "\n",
       "                                  translated_sentence  cluster  \\\n",
       "3421                      Is there a pharmacy nearby?        0   \n",
       "798                    The box is too heavy to carry.        0   \n",
       "2264                    This book sold well in Japan.        0   \n",
       "802   The policeman arrested him for drunken driving.        0   \n",
       "2260                   Did Tom tell you his password?        0   \n",
       "\n",
       "                                               words  average_count  \\\n",
       "3421  [มี, ร้านขายยา, ใน, บริเวณ, ใกล้เคียง, ไหม, ?]     147.857143   \n",
       "798            [กล่อง, หนัก, เกิน, กว่า, ที่จะ, แบก]      20.333333   \n",
       "2264        [หนังสือ, เล่ม, นี้, ขายดี, ใน, ญี่ปุ่น]      81.333333   \n",
       "802    [ตำรวจ, กุม, ตัว, เขา, เพราะ, เมา, แล้ว, ขับ]      55.000000   \n",
       "2260  [ทอม, บอก, รหัสผ่าน, เขา, กับ, คุณ, หรือเปล่า]     260.000000   \n",
       "\n",
       "      min_count  average_count_rank  min_count_rank  \n",
       "3421        1.0              1287.0          2924.5  \n",
       "798         1.0               101.0          2924.5  \n",
       "2264        1.0               586.0          2924.5  \n",
       "802         1.0               324.0          2924.5  \n",
       "2260        1.0              2571.0          2924.5  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the correct constants to describe the frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      rank         word   translation  frequency\n",
      "0        1          ฉัน           I..       1005\n",
      "10      11                                   275\n",
      "20      21           ทำ           Yes        196\n",
      "30      31       ไม่ได้            No        109\n",
      "40      41       ที่นี่          Here         89\n",
      "...    ...          ...           ...        ...\n",
      "2640  2641          จีน         China          1\n",
      "2650  2651           คอ      The neck          1\n",
      "2660  2661        เซลล์         Cells          1\n",
      "2670  2671  อย่างแน่นอน    Absolutely          1\n",
      "2680  2681    ใกล้เคียง  Close enough          1\n",
      "\n",
      "[269 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get every tenth word up to the nth most frequent word\n",
    "decimated_sorted_word_counts = sorted_word_counts[\n",
    "    sorted_word_counts.index % 10 == 0\n",
    "    ]\n",
    "\n",
    "decimated_sorted_word_counts = decimated_sorted_word_counts[\n",
    "    decimated_sorted_word_counts.index < 30000\n",
    "    ]\n",
    "\n",
    "print(decimated_sorted_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-66.915034   171.80666007   0.36692201   0.28239085]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "decimated_sorted_word_counts['cum_count'] = decimated_sorted_word_counts['frequency'].cumsum()\n",
    "\n",
    "# Normalise the cumulative count to between 0-100\n",
    "decimated_sorted_word_counts['norm_cum_count'] = (\n",
    "    decimated_sorted_word_counts['cum_count'] / decimated_sorted_word_counts['cum_count'].max()\n",
    "    ) * 100\n",
    "\n",
    "#centimated_df.count()\n",
    "decimated_sorted_word_counts['norm_cum_count'].plot(kind='line')\n",
    "\n",
    "def f(x, a, b, c, d):\n",
    "    return a + b / (1 + np.exp(-c * x**d))\n",
    "\n",
    "# Need to approximate the function for this distribution\n",
    "x = decimated_sorted_word_counts['rank']\n",
    "real_y = decimated_sorted_word_counts['norm_cum_count']\n",
    "\n",
    "initial_guess = [-100, 200, 0.4, 0.23]\n",
    "\n",
    "# Perform the curve fit\n",
    "(params, params_covariance) = curve_fit(f, x, real_y, p0=initial_guess)\n",
    "\n",
    "# Print the best-fit parameters\n",
    "print(params)\n",
    "\n",
    "approx_y = f(x, *params)\n",
    "\n",
    "# Overlay the function\n",
    "plt.plot(x, approx_y, color='r')  # 'r'\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real distribution can be very closely approximated using the appropriate parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Now the parameters of the function (a, b, c, d) have to be saved for the language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Get only sentences whose words are all in the top 1000 most frequent words in the corpus\n",
    "threshold_count = sorted_word_counts[\n",
    "    (sorted_word_counts.index > 999.0) & (sorted_word_counts.index < 1001.0)\n",
    "    ]['frequency'].values[0]\n",
    "\n",
    "top_thousand_word_sentences = df[df['min_count'] >= threshold_count]\n",
    "\n",
    "top_thousand_word_sentences.head(50)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From experimenting it seems like sorting by the min word count gives a better estimation of the\n",
    "# complexity of the sentence, but sometimes a simple sentence will contain one very obscure word\n",
    "# that unjustly shoots its value up. Taking the average word frequency often does the opposite:\n",
    "# Prioritises sentences that may contain lots of simple linking words such as de and la even if\n",
    "# the sentence may contain some complex words. A weighting of the two might be more indicative.\n",
    "# Would have to normalise their distributions first.\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['norm_min_count'] = df['min_count'] / df['min_count'].max()\n",
    "df['norm_average_count'] = df['average_count'] / df['average_count'].max()\n",
    "\n",
    "# Plot the distributions of min scores\n",
    "centimated_df = df[df.index % 100 == 0].sort_values(by='norm_min_count')['norm_min_count']\n",
    "\n",
    "#centimated_df.count()\n",
    "centimated_df.plot(kind='bar')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Plot the distributions of min scores\n",
    "centimated_df = df[df.index % 100 == 0].sort_values(by='norm_average_count')['norm_average_count']\n",
    "\n",
    "#centimated_df.count()\n",
    "centimated_df.plot(kind='bar')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I remove the extreme valuesthe normalised distribution of average frequency scores is pretty linear, whereas the distribution of minimum values (The rarest word in the sentence) is logarithmic. I therefore need to apply a transformation to one to enable a weighted average to be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Remove sentences whose average counts are within the top or bottom 10% and normalise so that\n",
    "# highest value equal to 1 and lowest value equal to zero\n",
    "bottom_threshold = df.quantile(0.1)\n",
    "top_threshold = df.quantile(0.9)\n",
    "\n",
    "df = df[\n",
    "    df['norm_average_count'] >= bottom_threshold\n",
    "    & df['norm_average_count'] <= top_threshold\n",
    "    ]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
