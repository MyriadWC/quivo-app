{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to go through my cleaned word list, split all sentences into their individual words, and create a new dataframe containing each individual word and the number of occurrences within the dataset to determine dataset word frequency (Which I will take as a proxy for overall word frequency). This isn't perfect and will ignore context-defined meaning in words that are spelled the same, as this will be counted as only one highly frequent word with multiple meanings rather than several less-frequent words that are spelled the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few issues will need to be solved here.\n",
    "\n",
    "1. There will be typos and misspellings in the dataset which as well as being less useful as a learning tool, will also lead to some words (particularly those with accents that have been forgotten or misplaced) being counted multiple times, so they'll somehow need to be joined together. I can't just remove all accents as this can change the meaning of a word entirely (côté vs. côte). The approach I took was to just remove any sentences containing the least frequent words and then remove them from the corpus, which will remove a big chunk of typos, but the more common ones could still be in there.\n",
    "\n",
    "2. Words that have been shortened due to consecutive vowels (l, d etc. could have multiple meanings such as le or la, or de or du), but since these are incredibly common words that will always have high scores it might not be so much of an issue for gauging the word's frequency. I just need to make sure to check less frequent words that have been shortened i.e. the presque in presqu'île, although I imagine this shortening would be sufficiently infrequent relative to its unshortened form as to have almost no bearing on its frequency score.\n",
    "\n",
    "3. I might have to set some custom rules for when to keep an apostrophe. Returning to my previous example, presqu'île should really be treated as a single word, and other such exceptions will exist. I just need to go down the frequency list and note them down.\n",
    "\n",
    "4. Different word types will have differing numbers of forms. Adjectives can be masculine or feminine (public, publique), plus others such as publiquement. Verbs can have a very large number of forms, meaning etre is likely to be separated far more than most adjectives which will have fewer forms, which could lead to forms of etre appearing below far less common words in the frequency list. For a language learner these forms can sometimes be similar, allowing a transfer of knowledge when learning new forms (If they know courir it doesn't take much to figure out that couru is just the past tense), while other times the different forms might represent entirely new strings of characters that must all be learnt independently from one another (aller, irai etc.). I'd say that since these are effectively different words that each have to be learned, it is reasonable that they are treated separately. I'm effectively mapping the frequency of different strings of letters appearing in a language.\n",
    "\n",
    "While this method for measuring word frequency is flawed, as long as I ensure that the sentences in my database are grammatically correct it should be useful enough as a tool to gauge sentence complexity via average word frequency, which is the ultimate aim. I could also use POS tagging by running each sentence through a pretrained hidden markov model or something similar to label word type, and have the frequency for each word+type pair. This would avoid the issue of words with multiple meanings being classified together (est for is and east etc.). I have to do this later for the single-word translation to work so it would make sense to do it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some weird caching issue so overriding for now\n",
    "constants.language_code = 'ru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = f\"../output_files/{constants.language_code}/step3_sentences.csv\"\n",
    "\n",
    "df = pd.read_csv(filepath, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     910425\n",
       "sentence               910425\n",
       "translated_sentence    910425\n",
       "dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regex\n",
    "\n",
    "fr_exceptions = [\n",
    "    \"[Aa]ujourd'hui\",\n",
    "    \"[Pp]resqu'île\",\n",
    "    \"[Qq]uelqu'un\",\n",
    "    \"[Dd]'accord\"\n",
    "    ]\n",
    "\n",
    "de_exceptions = []\n",
    "ru_exceptions = []\n",
    "\n",
    "exceptions = {\n",
    "    'fr': fr_exceptions,\n",
    "    'de': de_exceptions,\n",
    "    'ru': ru_exceptions\n",
    "    }[constants.language_code]\n",
    "\n",
    "word_regex = {\n",
    "    'fr': r'[a-zA-ZéèêëÉÈÊËàâäÀÂÄôöÔÖûüùÛÜÙçÇîÎïÏ]+',\n",
    "    'de': r'[a-zA-ZäöüÄÖÜß]+',\n",
    "    'ru': r'[А-Яа-яЁё]+'\n",
    "    }[constants.language_code]\n",
    "\n",
    "exceptions_regex = '|'.join(exceptions)\n",
    "\n",
    "# Not ideal but de empty exceptions was causing issues\n",
    "regex = {\n",
    "    'fr': fr'\\b{exceptions_regex}|{word_regex}\\b',\n",
    "    'de': fr'\\b{word_regex}\\b',\n",
    "    'ru': fr'\\b{word_regex}\\b'\n",
    "    }[constants.language_code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened_word_map = {\n",
    "    'j': 'je',\n",
    "    #'l': 'le', # Can be either so will handle after to speed up function\n",
    "    't': 'tu', # This will assign the t in a-t-on to tu for example, which will give tu a higher frequency than it should have, but it's only one very common word so I'm not going to address it\n",
    "    'd': 'de', # Need to check whether this is ever du\n",
    "    'c': 'ce',\n",
    "    's': 'se',\n",
    "    'qu': 'que',\n",
    "    'm': 'me',\n",
    "    'n': 'ne',\n",
    "    }\n",
    "\n",
    "def scan_sentence(sentence: str, unique_word_counts: defaultdict) -> defaultdict:\n",
    "    '''Scans a sentence to get its words and updates the unique word count dictionary.\n",
    "    Local unique_word_counts points to global variable so can update directly. The use\n",
    "    of a default dict means we don't have to check if a key is in the dictionary before\n",
    "    adding it as it will initialise to 1.\n",
    "\n",
    "    Using a dict instead of a dataframe means there's O(1) time complexity for insertions\n",
    "    and lookups, and using a defaultdict to avoid an additional check means this runs\n",
    "    incredibly quickly on even very large datasets.\n",
    "    '''\n",
    "\n",
    "    # Split all words in the sentence by word boundaries (Split uninclusively at punctuation or non-alphanumeric characters)\n",
    "    words = re.findall(regex, sentence) # Words only\n",
    "\n",
    "    # Set all words to lowercase\n",
    "    words = [word.lower() for word in words]\n",
    "\n",
    "    # Replace any shortened words with their full-length version\n",
    "    if constants.language_code == 'fr':\n",
    "        words = [shortened_word_map.get(word, word) for word in words]\n",
    "\n",
    "    for word in words:\n",
    "\n",
    "        # Add 1 to count. If word doesn't exist adds in new entry\n",
    "        unique_word_counts[word] += 1\n",
    "\n",
    "    return unique_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>translated_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23423900.0</td>\n",
       "      <td>Ну, знаешь, как это обычно с ней бывает.</td>\n",
       "      <td>You know how it is with her.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12658818.0</td>\n",
       "      <td>Так что вам срочно нужно начать химиотерапию. ...</td>\n",
       "      <td>So, yeah, we're gonna wanna start a round of c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13578334.0</td>\n",
       "      <td>Чувак, расслабься. Люди подтянутся, отвечаю. -...</td>\n",
       "      <td>[YACHT'S \"PSYCHIC CITY (CLASSIXX REMIX)\" PLAYI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18310616.0</td>\n",
       "      <td>Все время сидел за компьютером.</td>\n",
       "      <td>He spends all day on his computer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8759716.0</td>\n",
       "      <td>Я уже на 10 минут опаздываю. Давай быстрее!</td>\n",
       "      <td>I'm already 10 minutes late, hurry!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                           sentence  \\\n",
       "0  23423900.0           Ну, знаешь, как это обычно с ней бывает.   \n",
       "1  12658818.0  Так что вам срочно нужно начать химиотерапию. ...   \n",
       "2  13578334.0  Чувак, расслабься. Люди подтянутся, отвечаю. -...   \n",
       "3  18310616.0                    Все время сидел за компьютером.   \n",
       "4   8759716.0        Я уже на 10 минут опаздываю. Давай быстрее!   \n",
       "\n",
       "                                 translated_sentence  \n",
       "0                       You know how it is with her.  \n",
       "1  So, yeah, we're gonna wanna start a round of c...  \n",
       "2  [YACHT'S \"PSYCHIC CITY (CLASSIXX REMIX)\" PLAYI...  \n",
       "3                 He spends all day on his computer.  \n",
       "4                I'm already 10 minutes late, hurry!  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_word_counts = pd.DataFrame(columns=['word', 'count'])\n",
    "unique_word_counts_dict = defaultdict(int)\n",
    "\n",
    "for sentence in df['sentence'].values:\n",
    "\n",
    "    #unique_word_counts = scan_sentence(sentence, unique_word_counts)\n",
    "    unique_word_counts_dict = scan_sentence(sentence, unique_word_counts_dict)\n",
    "\n",
    "# Convert the dictionary to a list of tuples\n",
    "unique_word_counts = list(unique_word_counts_dict.items())\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "unique_word_counts = pd.DataFrame(unique_word_counts, columns=['word', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to distribute l appropriately between le and la counts. Based off my previous counts la occurs\n",
    "# 55% of the time\n",
    "if (constants.language_code == 'fr'):\n",
    "\n",
    "    le_frequency = 0.45\n",
    "\n",
    "    l_count = unique_word_counts[unique_word_counts['word'] == 'l']['count'].values[0]\n",
    "\n",
    "    unique_word_counts.loc[unique_word_counts['word'] == 'le', 'count'] += l_count * le_frequency\n",
    "    unique_word_counts.loc[unique_word_counts['word'] == 'la','count'] += l_count * (1 - le_frequency)\n",
    "\n",
    "    # Remove l row\n",
    "    unique_word_counts = unique_word_counts.drop(\n",
    "        unique_word_counts[unique_word_counts['word'] == 'l'].index\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# A parallel approach to creating the unique word counts for when the dataset becomes too big to feasibly handle\\n# with a single python process\\n\\nimport numpy as np\\nimport multiprocessing\\n\\n# check how many cores are available\\nnum_cpus = multiprocessing.cpu_count()\\n\\nnum_chunks = 4\\n\\nif num_cpus < num_chunks:\\n    raise SystemError(f\\'Insufficient number of CPUs ({num_cpus}) for chosen number of chunks ({num_chunks})\\')\\n\\n# split dataset into chunks\\nchunks = np.array_split(df, num_chunks)\\n\\n# Define the function to be run in each process\\ndef process_chunk(chunk):\\n    \"\"\"Calculates the unique word counts for a given chunk of the sentences\\n    \"\"\"\\n\\n    unique_word_counts = pd.DataFrame(columns=[\\'word\\', \\'count\\'])\\n\\n    # Perform your operations on the chunk here\\n    # For example, compute the mean of each column\\n    for sentence in chunk[\\'sentence\\'].values:\\n\\n        unique_word_counts = scan_sentence(sentence, unique_word_counts)\\n\\n    return unique_word_counts\\n\\n# Create a pool of processes\\nwith multiprocessing.Pool(num_chunks) as p:\\n    # Apply the function to each chunk in the pool of processes\\n    results = p.map(process_chunk, chunks)\\n\\n# Now \\'results\\' is a list of the results from each process\\nfor i, chunk_unique_word_counts in enumerate(results):\\n    pass\\n    # TODO: Combine the unique word count dataframes from each process into one and save\\n\\n'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# A parallel approach to creating the unique word counts for when the dataset becomes too big to feasibly handle\n",
    "# with a single python process\n",
    "\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "# check how many cores are available\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "num_chunks = 4\n",
    "\n",
    "if num_cpus < num_chunks:\n",
    "    raise SystemError(f'Insufficient number of CPUs ({num_cpus}) for chosen number of chunks ({num_chunks})')\n",
    "\n",
    "# split dataset into chunks\n",
    "chunks = np.array_split(df, num_chunks)\n",
    "\n",
    "# Define the function to be run in each process\n",
    "def process_chunk(chunk):\n",
    "    \"\"\"Calculates the unique word counts for a given chunk of the sentences\n",
    "    \"\"\"\n",
    "\n",
    "    unique_word_counts = pd.DataFrame(columns=['word', 'count'])\n",
    "\n",
    "    # Perform your operations on the chunk here\n",
    "    # For example, compute the mean of each column\n",
    "    for sentence in chunk['sentence'].values:\n",
    "\n",
    "        unique_word_counts = scan_sentence(sentence, unique_word_counts)\n",
    "\n",
    "    return unique_word_counts\n",
    "\n",
    "# Create a pool of processes\n",
    "with multiprocessing.Pool(num_chunks) as p:\n",
    "    # Apply the function to each chunk in the pool of processes\n",
    "    results = p.map(process_chunk, chunks)\n",
    "\n",
    "# Now 'results' is a list of the results from each process\n",
    "for i, chunk_unique_word_counts in enumerate(results):\n",
    "    pass\n",
    "    # TODO: Combine the unique word count dataframes from each process into one and save\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having looked at the dataset, most words that appear three times or fewer in the dataset are either typos or\n",
    "sufficiently obscure that I should probably remove any sentences that contain these words. The logarithmic\n",
    "nature of word frequency distributions in a text corpus means this will cause the number of unique words in\n",
    "the corpus to drop significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of times a word has to appear in the corpus for it to be kept\n",
    "obscurity_cutoff = 16\n",
    "\n",
    "# Get list of words that occur less than this in the dataset\n",
    "obscure_words = unique_word_counts[unique_word_counts['count'] < obscurity_cutoff]['word'].to_list()\n",
    "\n",
    "# Convert the list of words to a set for faster lookup\n",
    "obscure_words = set(obscure_words)\n",
    "\n",
    "# Split the sentences into words (Must use the same regex as was used to create the original word frequency list)\n",
    "df['words'] = df['sentence'].apply(lambda x: re.findall(regex, x.lower()))\n",
    "\n",
    "# Remove any rows where the sentence contains one of the obscure words\n",
    "df = df[~df['words'].apply(lambda x: any(word in obscure_words for word in x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     470413\n",
       "sentence               470413\n",
       "translated_sentence    470413\n",
       "words                  470413\n",
       "dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has removed hundreds of thousands of sentences from the dataset and drastically reduced the number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>translated_sentence</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23423900.0</td>\n",
       "      <td>Ну, знаешь, как это обычно с ней бывает.</td>\n",
       "      <td>You know how it is with her.</td>\n",
       "      <td>[ну, знаешь, как, это, обычно, с, ней, бывает]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18310616.0</td>\n",
       "      <td>Все время сидел за компьютером.</td>\n",
       "      <td>He spends all day on his computer.</td>\n",
       "      <td>[все, время, сидел, за, компьютером]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8759716.0</td>\n",
       "      <td>Я уже на 10 минут опаздываю. Давай быстрее!</td>\n",
       "      <td>I'm already 10 minutes late, hurry!</td>\n",
       "      <td>[я, уже, на, минут, опаздываю, давай, быстрее]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9276443.0</td>\n",
       "      <td>Сам знаешь, дети часто участвуют в чём-то за к...</td>\n",
       "      <td>I mean, you know, kids are going to do what th...</td>\n",
       "      <td>[сам, знаешь, дети, часто, участвуют, в, чём, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2002885.0</td>\n",
       "      <td>Я вас не понимаю, мистер Бейли.</td>\n",
       "      <td>I don't understand, Mr. Bailey.</td>\n",
       "      <td>[я, вас, не, понимаю, мистер, бейли]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                           sentence  \\\n",
       "0  23423900.0           Ну, знаешь, как это обычно с ней бывает.   \n",
       "3  18310616.0                    Все время сидел за компьютером.   \n",
       "4   8759716.0        Я уже на 10 минут опаздываю. Давай быстрее!   \n",
       "5   9276443.0  Сам знаешь, дети часто участвуют в чём-то за к...   \n",
       "6   2002885.0                    Я вас не понимаю, мистер Бейли.   \n",
       "\n",
       "                                 translated_sentence  \\\n",
       "0                       You know how it is with her.   \n",
       "3                 He spends all day on his computer.   \n",
       "4                I'm already 10 minutes late, hurry!   \n",
       "5  I mean, you know, kids are going to do what th...   \n",
       "6                    I don't understand, Mr. Bailey.   \n",
       "\n",
       "                                               words  \n",
       "0     [ну, знаешь, как, это, обычно, с, ней, бывает]  \n",
       "3               [все, время, сидел, за, компьютером]  \n",
       "4     [я, уже, на, минут, опаздываю, давай, быстрее]  \n",
       "5  [сам, знаешь, дети, часто, участвуют, в, чём, ...  \n",
       "6               [я, вас, не, понимаю, мистер, бейли]  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nconn = engine.connect()\\n\\n# create a metadata object and reflect the table\\nmetadata = MetaData()\\ntable = Table('api_appuser_known_words', metadata, autoload_with=engine)\\n\\n# create a delete object and execute it to remove the known words table first\\ndelete_stmt = table.delete()\\nconn.execute(delete_stmt)\\n\\n# Now update the word data table with the new unique words\\nsorted_word_counts.to_sql(f'language_app_{constants.language_code}worddata', engine, if_exists='replace')\\n\""
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, Table, MetaData\n",
    "\n",
    "# Remove the abscure words from the word counts dataframe and save new dataset and word counts\n",
    "unique_word_counts = unique_word_counts[unique_word_counts['count'] >= obscurity_cutoff]\n",
    "\n",
    "# Remove NaN\n",
    "unique_words_counts = unique_word_counts[unique_word_counts['word'].isna()]\n",
    "\n",
    "# Sort and save the frequency list into final tables\n",
    "sorted_word_counts = unique_word_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "#sorted_word_counts['rank'] = sorted_word_counts['count'].rank(ascending=False)\n",
    "\n",
    "# Reset the index\n",
    "sorted_word_counts = sorted_word_counts.reset_index(drop=True)\n",
    "\n",
    "sorted_word_counts['rank'] = sorted_word_counts.index + 1\n",
    "\n",
    "sorted_word_counts = sorted_word_counts[['rank', 'word', 'count']]\n",
    "\n",
    "sorted_word_counts.to_csv(f'../output_files/{constants.language_code}/step4_unique_word_counts.csv', sep='\\t')\n",
    "\n",
    "# Update table in sqlalchemy------------------------------------\n",
    "\n",
    "# Note that you first have to delete the many to many 'words_known' relationship between\n",
    "# users and the word data, so use with caution.\n",
    "engine = create_engine('postgresql://quivo_default:s567tyug328726hj9j83@localhost:5432/quivo')\n",
    "'''\n",
    "conn = engine.connect()\n",
    "\n",
    "# create a metadata object and reflect the table\n",
    "metadata = MetaData()\n",
    "table = Table('api_appuser_known_words', metadata, autoload_with=engine)\n",
    "\n",
    "# create a delete object and execute it to remove the known words table first\n",
    "delete_stmt = table.delete()\n",
    "conn.execute(delete_stmt)\n",
    "\n",
    "# Now update the word data table with the new unique words\n",
    "sorted_word_counts.to_sql(f'language_app_{constants.language_code}worddata', engine, if_exists='replace')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Keep every 100th value for quicker plotting\n",
    "#sorted_word_counts[sorted_word_counts['count'] > 1]['count'].plot(kind='bar')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating word frequency-based sentence complexity scores\n",
    "\n",
    "Now we know all word frequencies, this information can be used to figure out the average sentence complexity of words within each sentence to get a preliminary idea of which sentences will be more difficult to understand / more or less useful for a language learner at any given level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toby Usher\\AppData\\Local\\Temp\\ipykernel_16488\\3641391163.py:18: FutureWarning: Returning a DataFrame from Series.apply when the supplied function returns a Series is deprecated and will be removed in a future version.\n",
      "  df[['average_count', 'min_count']] = df['words'].apply(calculate_average_and_min, args=(unique_word_counts_dict,))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Use the original word counts dict (Still contains the obscure words but should still be quicker)\n",
    "# to calculate the average and min word counts for each sentence\n",
    "\n",
    "def calculate_average_and_min(row, word_counts):\n",
    "\n",
    "    # Gets all counts for the sentence. Defaults to zero if word missing although this should\n",
    "    # never happen\n",
    "    counts = [word_counts.get(word, 0) for word in row]\n",
    "\n",
    "    if not counts:\n",
    "        return pd.Series([0, 0])\n",
    "    \n",
    "    return pd.Series([np.mean(counts), np.min(counts)])\n",
    "\n",
    "# Mean of all word count frequencies, minimum word frequency (rarest word) in sentence\n",
    "df[['average_count', 'min_count']] = df['words'].apply(calculate_average_and_min, args=(unique_word_counts_dict,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rank columns for average and min counts\n",
    "df['average_count_rank'] = df['average_count'].rank(ascending=True)\n",
    "df['min_count_rank'] = df['min_count'].rank(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cluster' not in df.columns:\n",
    "    df['cluster'] = 0\n",
    "\n",
    "# Add in placeholder for translation for now\n",
    "#df['translated_sentence'] = 'Translation'\n",
    "\n",
    "# Remove any translations with a tab in\n",
    "df['translated_sentence'] = df['translated_sentence'].str.replace(r'.*\\t.*', '', regex=True)\n",
    "\n",
    "# Put the dataframe in the correct format for the Django model\n",
    "df = df[[\n",
    "    'sentence',\n",
    "    'translated_sentence',\n",
    "    'cluster',\n",
    "    'words',\n",
    "    'average_count',\n",
    "    'min_count',\n",
    "    'average_count_rank',\n",
    "    'min_count_rank'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "ordered_df = df.sort_values(by='min_count', ascending=True)\n",
    "ordered_df.to_csv(f'../output_files/{constants.language_code}/step4_sentences.csv', sep='\\t')\n",
    "\n",
    "ordered_df.to_sql(f'language_app_{constants.language_code}sentence', engine, if_exists='replace')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>translated_sentence</th>\n",
       "      <th>cluster</th>\n",
       "      <th>words</th>\n",
       "      <th>average_count</th>\n",
       "      <th>min_count</th>\n",
       "      <th>average_count_rank</th>\n",
       "      <th>min_count_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>761876</th>\n",
       "      <td>150)}いくつもの空を描いた 150)}いくつもの空を描いた</td>\n",
       "      <td>80)}Koko wa kitto hakanai kokoro 1060)}This mu...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>470411.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264303</th>\n",
       "      <td>میدونی چقدر سعی کردم اونو آروم کنم؟</td>\n",
       "      <td>You know how much I tried to turn her down?</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>470411.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240920</th>\n",
       "      <td>Рядοм сο старинοй Оскарοм Уайлдοм?</td>\n",
       "      <td>Père Lachaise? Next to dear old Oscar?</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>470411.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563830</th>\n",
       "      <td>.ببین، این چیزی که فکر میکنی نیست</td>\n",
       "      <td>Look, this is not what you think.</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>470411.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39984</th>\n",
       "      <td>Не должен был дожить до этого возраста.</td>\n",
       "      <td>Wasn't supposed to make it this far.</td>\n",
       "      <td>0</td>\n",
       "      <td>[не, должен, был, дожить, до, этого, возраста]</td>\n",
       "      <td>39921.714286</td>\n",
       "      <td>16.0</td>\n",
       "      <td>214165.0</td>\n",
       "      <td>465428.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sentence  \\\n",
       "761876          150)}いくつもの空を描いた 150)}いくつもの空を描いた   \n",
       "264303      میدونی چقدر سعی کردم اونو آروم کنم؟   \n",
       "240920       Рядοм сο старинοй Оскарοм Уайлдοм?   \n",
       "563830        .ببین، این چیزی که فکر میکنی نیست   \n",
       "39984   Не должен был дожить до этого возраста.   \n",
       "\n",
       "                                      translated_sentence  cluster  \\\n",
       "761876  80)}Koko wa kitto hakanai kokoro 1060)}This mu...        0   \n",
       "264303        You know how much I tried to turn her down?        0   \n",
       "240920             Père Lachaise? Next to dear old Oscar?        0   \n",
       "563830                  Look, this is not what you think.        0   \n",
       "39984                Wasn't supposed to make it this far.        0   \n",
       "\n",
       "                                                 words  average_count  \\\n",
       "761876                                              []       0.000000   \n",
       "264303                                              []       0.000000   \n",
       "240920                                              []       0.000000   \n",
       "563830                                              []       0.000000   \n",
       "39984   [не, должен, был, дожить, до, этого, возраста]   39921.714286   \n",
       "\n",
       "        min_count  average_count_rank  min_count_rank  \n",
       "761876        0.0                 2.5        470411.5  \n",
       "264303        0.0                 2.5        470411.5  \n",
       "240920        0.0                 2.5        470411.5  \n",
       "563830        0.0                 2.5        470411.5  \n",
       "39984        16.0            214165.0        465428.5  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the correct constants to describe the frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        rank       word   count\n",
      "0          1          я  239058\n",
      "10        11         он   64875\n",
      "20        21          а   43566\n",
      "30        31          о   32109\n",
      "40        41        был   22084\n",
      "...      ...        ...     ...\n",
      "29950  29951     тяжким      16\n",
      "29960  29961  федерацию      16\n",
      "29970  29971      химик      16\n",
      "29980  29981    критика      16\n",
      "29990  29991     колёса      16\n",
      "\n",
      "[3000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get every tenth word up to the nth most frequent word\n",
    "decimated_sorted_word_counts = sorted_word_counts[\n",
    "    sorted_word_counts.index % 10 == 0\n",
    "    ]\n",
    "\n",
    "decimated_sorted_word_counts = decimated_sorted_word_counts[\n",
    "    decimated_sorted_word_counts.index < 30000\n",
    "    ]\n",
    "\n",
    "print(decimated_sorted_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.68531978e+02  2.83552212e+02  7.16827478e-01  1.34958363e-01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "decimated_sorted_word_counts['cum_count'] = decimated_sorted_word_counts['count'].cumsum()\n",
    "\n",
    "# Normalise the cumulative count to between 0-100\n",
    "decimated_sorted_word_counts['norm_cum_count'] = (\n",
    "    decimated_sorted_word_counts['cum_count'] / decimated_sorted_word_counts['cum_count'].max()\n",
    "    ) * 100\n",
    "\n",
    "#centimated_df.count()\n",
    "decimated_sorted_word_counts['norm_cum_count'].plot(kind='line')\n",
    "\n",
    "def f(x, a, b, c, d):\n",
    "    return a + b / (1 + np.exp(-c * x**d))\n",
    "\n",
    "# Need to approximate the function for this distribution\n",
    "x = decimated_sorted_word_counts['rank']\n",
    "real_y = decimated_sorted_word_counts['norm_cum_count']\n",
    "\n",
    "initial_guess = [-100, 200, 0.4, 0.23]\n",
    "\n",
    "# Perform the curve fit\n",
    "(params, params_covariance) = curve_fit(f, x, real_y, p0=initial_guess)\n",
    "\n",
    "# Print the best-fit parameters\n",
    "print(params)\n",
    "\n",
    "approx_y = f(x, *params)\n",
    "\n",
    "# Overlay the function\n",
    "plt.plot(x, approx_y, color='r')  # 'r'\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real distribution can be very closely approximated using the appropriate parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Now the parameters of the function (a, b, c, d) have to be saved for the language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Get only sentences whose words are all in the top 1000 most frequent words in the corpus\\nthreshold_count = sorted_word_counts[\\n    (sorted_word_counts.index > 999.0) & (sorted_word_counts.index < 1001.0)\\n    ]['count'].values[0]\\n\\ntop_thousand_word_sentences = df[df['min_count'] >= threshold_count]\\n\\ntop_thousand_word_sentences.head(50)\\n\""
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Get only sentences whose words are all in the top 1000 most frequent words in the corpus\n",
    "threshold_count = sorted_word_counts[\n",
    "    (sorted_word_counts.index > 999.0) & (sorted_word_counts.index < 1001.0)\n",
    "    ]['count'].values[0]\n",
    "\n",
    "top_thousand_word_sentences = df[df['min_count'] >= threshold_count]\n",
    "\n",
    "top_thousand_word_sentences.head(50)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.pyplot as plt\\n\\ndf['norm_min_count'] = df['min_count'] / df['min_count'].max()\\ndf['norm_average_count'] = df['average_count'] / df['average_count'].max()\\n\\n# Plot the distributions of min scores\\ncentimated_df = df[df.index % 100 == 0].sort_values(by='norm_min_count')['norm_min_count']\\n\\n#centimated_df.count()\\ncentimated_df.plot(kind='bar')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From experimenting it seems like sorting by the min word count gives a better estimation of the\n",
    "# complexity of the sentence, but sometimes a simple sentence will contain one very obscure word\n",
    "# that unjustly shoots its value up. Taking the average word frequency often does the opposite:\n",
    "# Prioritises sentences that may contain lots of simple linking words such as de and la even if\n",
    "# the sentence may contain some complex words. A weighting of the two might be more indicative.\n",
    "# Would have to normalise their distributions first.\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['norm_min_count'] = df['min_count'] / df['min_count'].max()\n",
    "df['norm_average_count'] = df['average_count'] / df['average_count'].max()\n",
    "\n",
    "# Plot the distributions of min scores\n",
    "centimated_df = df[df.index % 100 == 0].sort_values(by='norm_min_count')['norm_min_count']\n",
    "\n",
    "#centimated_df.count()\n",
    "centimated_df.plot(kind='bar')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Plot the distributions of min scores\\ncentimated_df = df[df.index % 100 == 0].sort_values(by='norm_average_count')['norm_average_count']\\n\\n#centimated_df.count()\\ncentimated_df.plot(kind='bar')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Plot the distributions of min scores\n",
    "centimated_df = df[df.index % 100 == 0].sort_values(by='norm_average_count')['norm_average_count']\n",
    "\n",
    "#centimated_df.count()\n",
    "centimated_df.plot(kind='bar')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I remove the extreme valuesthe normalised distribution of average frequency scores is pretty linear, whereas the distribution of minimum values (The rarest word in the sentence) is logarithmic. I therefore need to apply a transformation to one to enable a weighted average to be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Remove sentences whose average counts are within the top or bottom 10% and normalise so that\\n# highest value equal to 1 and lowest value equal to zero\\nbottom_threshold = df.quantile(0.1)\\ntop_threshold = df.quantile(0.9)\\n\\ndf = df[\\n    df['norm_average_count'] >= bottom_threshold\\n    & df['norm_average_count'] <= top_threshold\\n    ]\\n\""
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Remove sentences whose average counts are within the top or bottom 10% and normalise so that\n",
    "# highest value equal to 1 and lowest value equal to zero\n",
    "bottom_threshold = df.quantile(0.1)\n",
    "top_threshold = df.quantile(0.9)\n",
    "\n",
    "df = df[\n",
    "    df['norm_average_count'] >= bottom_threshold\n",
    "    & df['norm_average_count'] <= top_threshold\n",
    "    ]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
